{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af99a87",
   "metadata": {},
   "source": [
    "# Cálculo de Tasa de Defunción seleccionada por zona metropolitana\n",
    "## **Instrucciones:**\n",
    "Cambia el directorio del conjunto de datos y el directorio de trabajo en el primer bloque. Para conocer las opciones de defunciones en lista mexicana debes de revisar elconjunto de defunciones registradas - catalogos - lista_mexicana.csv\n",
    "\n",
    "## **Links de descarga:**\n",
    "**Estadísticas de Defunciones Registradas:** https://www.inegi.org.mx/programas/edr/#datos_abiertos\n",
    "**Crecimiento Demográfico:** https://www.gob.mx/cms/uploads/attachment/file/918028/BD_municipales_portada_regiones_FINAL.pdf\n",
    "**Características de Metrópolis:** https://datos.gob.mx/dataset/metropolis_mexico_2020/resource/622497d1-7a92-43e1-8279-e8c286889509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3daee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 0) Setup: rutas, parámetros, lecturas (solo aquí)\n",
    "# ================================================================\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------\n",
    "# Base repo (según tu estructura)\n",
    "# -------------------------\n",
    "DIR_REPO = Path(r\"D:\\Contenido\\2025_12\\Suicidios_Navidad\\Repositorio\")\n",
    "DIR_DATA = DIR_REPO / \"Data\"\n",
    "DIR_OUTPUT = DIR_REPO / \"Output\"\n",
    "\n",
    "# -------------------------\n",
    "# EDR\n",
    "# -------------------------\n",
    "Dir_Defunciones = Path(r\"D:\\Data Qgis\\México\\Defuncciones\\conjunto_de_datos_edr2024_csv (1)\\conjunto_de_datos\")\n",
    "ARCHIVO_CONJ_DEF = \"conjunto_de_datos_defunciones_registradas24_csv.csv\"\n",
    "\n",
    "# -------------------------\n",
    "# Metro\n",
    "# -------------------------\n",
    "Dir_Metropolis = DIR_DATA / \"Metro\"\n",
    "ARCHIVO_Metropoli_Bridge = \"Bridge_ZonasMetro.csv\"\n",
    "ARCHIVO_Carateristicas_Metro = \"metropolis_caracteristicas.csv\"\n",
    "ARCHIVO_Proyecciones_Demograficas = \"Indicadores_Dem_Mun.csv\"\n",
    "\n",
    "# -------------------------\n",
    "# Catálogos\n",
    "# -------------------------\n",
    "DIR_CATALOGOS = DIR_DATA / \"EDR_Catalogos\"\n",
    "CAT_PAISES = \"paises.csv\"\n",
    "CAT_OCUPACION = \"ocupacion.csv\"\n",
    "CAT_ESCOLARIDAD = \"escolaridad.csv\"\n",
    "CAT_EDO_CIVIL = \"estado_civil.csv\"\n",
    "\n",
    "# ICD-10 (catálogo original) y bridge ya generado (está en Output según tu screenshot)\n",
    "ICD_SUIC_CAT = \"ICD-10_suicidio.csv\"\n",
    "ICD_SUIC_BRIDGE = DIR_OUTPUT / \"ICD-10_suicidio_bridge.csv\"\n",
    "\n",
    "# -------------------------\n",
    "# Parámetros suicidio\n",
    "# -------------------------\n",
    "ICD10_INI = \"X60\"\n",
    "ICD10_FIN = \"X84\"\n",
    "RURAL_TLOC = {1, 2, 99}\n",
    "\n",
    "# Outputs\n",
    "OUT_POB_ZM_2024 = DIR_OUTPUT / \"ZonaMetro_Pob2024.csv\"\n",
    "OUT_CLEAN = DIR_OUTPUT / \"Suicidios_Clean.csv\"\n",
    "OUT_ANALISIS_ZM = DIR_OUTPUT / \"AnalisisVentanas8d_ZM.csv\"\n",
    "\n",
    "# -------------------------\n",
    "# Lecturas (solo aquí)\n",
    "# -------------------------\n",
    "df_edr = pd.read_csv(Dir_Defunciones / ARCHIVO_CONJ_DEF, encoding=\"latin1\", low_memory=False)\n",
    "\n",
    "df_bridge = pd.read_csv(Dir_Metropolis / ARCHIVO_Metropoli_Bridge, encoding=\"utf-8\")\n",
    "df_metro_car = pd.read_csv(Dir_Metropolis / ARCHIVO_Carateristicas_Metro, encoding=\"utf-8\")\n",
    "df_proy = pd.read_csv(Dir_Metropolis / ARCHIVO_Proyecciones_Demograficas, encoding=\"latin1\")\n",
    "\n",
    "df_paises = pd.read_csv(DIR_CATALOGOS / CAT_PAISES, encoding=\"utf-8\")\n",
    "df_ocup = pd.read_csv(DIR_CATALOGOS / CAT_OCUPACION, encoding=\"utf-8\")\n",
    "df_esco = pd.read_csv(DIR_CATALOGOS / CAT_ESCOLARIDAD, encoding=\"utf-8\")\n",
    "df_eciv = pd.read_csv(DIR_CATALOGOS / CAT_EDO_CIVIL, encoding=\"utf-8\")\n",
    "\n",
    "# Bridge ICD ya generado (si no existe, aquí fallará y sabrás que te falta correr el script del bridge)\n",
    "df_icd_bridge = pd.read_csv(ICD_SUIC_BRIDGE, encoding=\"utf-8\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9fc22d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Contenido/2025_12/Suicidios_Navidad/Repositorio/Output/ZonaMetro_Pob2024.csv')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Paso 1.1 - Población 2024 por Zona Metropolitana (NO imports/lecturas)\n",
    "# ================================================================\n",
    "\n",
    "# -------------------------\n",
    "# 1) Estandarización de claves (NO cambiar nombres de columnas)\n",
    "# -------------------------\n",
    "df_metro_car = df_metro_car.copy()\n",
    "df_bridge = df_bridge.copy()\n",
    "df_proy = df_proy.copy()\n",
    "\n",
    "df_metro_car[\"clave_metropoli\"] = df_metro_car[\"clave_metropoli\"].astype(str).str.strip()\n",
    "df_metro_car[\"nombre\"] = df_metro_car[\"nombre\"].astype(str).str.strip()\n",
    "df_metro_car[\"poblacion\"] = pd.to_numeric(df_metro_car[\"poblacion\"], errors=\"coerce\")\n",
    "\n",
    "df_bridge[\"Cve_Metro\"] = df_bridge[\"Cve_Metro\"].astype(str).str.strip()\n",
    "df_bridge[\"Cve_mun\"]   = df_bridge[\"Cve_mun\"].astype(str).str.strip().str.zfill(5)\n",
    "\n",
    "df_proy[\"CLAVE\"] = df_proy[\"CLAVE\"].astype(str).str.strip().str.zfill(5)\n",
    "df_proy[\"AÑO\"]   = pd.to_numeric(df_proy[\"AÑO\"], errors=\"coerce\")\n",
    "df_proy[\"POB_MIT_MUN\"] = pd.to_numeric(df_proy[\"POB_MIT_MUN\"], errors=\"coerce\")\n",
    "\n",
    "# -------------------------\n",
    "# 2) Filtrar 2024\n",
    "# -------------------------\n",
    "df_proy_2024 = (\n",
    "    df_proy.loc[df_proy[\"AÑO\"] == 2024, [\"CLAVE\", \"AÑO\", \"POB_MIT_MUN\"]]\n",
    "    .dropna(subset=[\"CLAVE\", \"POB_MIT_MUN\"])\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 3) Join municipio -> ZM y agregación por ZM\n",
    "# -------------------------\n",
    "df_mun_metro_2024 = df_bridge.merge(\n",
    "    df_proy_2024,\n",
    "    left_on=\"Cve_mun\",\n",
    "    right_on=\"CLAVE\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "pob2024_zm = (\n",
    "    df_mun_metro_2024\n",
    "    .groupby(\"Cve_Metro\", as_index=False)[\"POB_MIT_MUN\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"Cve_Metro\": \"clave_metropoli\", \"POB_MIT_MUN\": \"poblacion2024\"})\n",
    ")\n",
    "\n",
    "df_zm_pob = df_metro_car.merge(\n",
    "    pob2024_zm,\n",
    "    on=\"clave_metropoli\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\"\n",
    ")\n",
    "\n",
    "df_zm_pob = df_zm_pob.rename(columns={\"poblacion\": \"poblacion2020\"})\n",
    "df_zm_pob = df_zm_pob[[\"clave_metropoli\", \"nombre\", \"poblacion2020\", \"poblacion2024\"]].copy()\n",
    "\n",
    "# ================================================================\n",
    "# Export - Población ZM 2024 (NO imports/lecturas)\n",
    "# ================================================================\n",
    "OUT_POB_ZM_2024.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_zm_pob.to_csv(OUT_POB_ZM_2024, index=False, encoding=\"utf-8\")\n",
    "OUT_POB_ZM_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "311fe8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Contenido/2025_12/Suicidios_Navidad/Repositorio/Output/ICD-10_suicidio_bridge.csv')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "\n",
    "RUTA_OUT = DIR_OUTPUT / \"ICD-10_suicidio_bridge.csv\"\n",
    "\n",
    "df = pd.read_csv(RUTA_ICD, encoding=\"utf-8\")\n",
    "\n",
    "# Detectar columnas\n",
    "cols_lower = {c.lower(): c for c in df.columns}\n",
    "col_codigo = cols_lower.get(\"cve\") or cols_lower.get(\"codigo\") or cols_lower.get(\"code\")\n",
    "col_desc   = cols_lower.get(\"descrip\") or cols_lower.get(\"descripcion\") or cols_lower.get(\"desc\")\n",
    "\n",
    "if col_codigo is None or col_desc is None:\n",
    "    raise ValueError(f\"No pude detectar columnas código/desc. Columnas: {list(df.columns)}\")\n",
    "\n",
    "df = df.rename(columns={col_codigo: \"Codigo\", col_desc: \"Descripcion\"}).copy()\n",
    "\n",
    "# ================================================================\n",
    "# NORMALIZACIÓN CLAVE (arregla ESCUELAS\", OTRAS...)\n",
    "# ================================================================\n",
    "desc = (\n",
    "    df[\"Descripcion\"].astype(str).str.upper().str.strip()\n",
    "    .str.replace('\"', '', regex=False)                 # quita comillas\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)             # normaliza espacios\n",
    "    .str.replace(r\"\\s*,\\s*\", \",\", regex=True)         # coma sin espacios alrededor\n",
    ")\n",
    "\n",
    "PREF_ENV     = \"ENVENENAMIENTO AUTOINFLIGIDO INTENCIONALMENTE POR,Y EXPOSICION A\"\n",
    "PREF_LES_POR = \"LESION AUTOINFLIGIDA INTENCIONALMENTE POR\"\n",
    "PREF_LES_AL  = \"LESION AUTOINFLIGIDA INTENCIONALMENTE AL\"\n",
    "\n",
    "is_env = desc.str.startswith(PREF_ENV)\n",
    "is_les = desc.str.startswith(PREF_LES_POR) | desc.str.startswith(PREF_LES_AL)\n",
    "\n",
    "tipo = pd.Series(pd.NA, index=df.index, dtype=\"object\")\n",
    "tipo.loc[is_env] = \"Envenenamiento\"\n",
    "tipo.loc[is_les] = \"Lesión\"\n",
    "\n",
    "rest = desc.copy()\n",
    "rest.loc[is_env] = rest.loc[is_env].str[len(PREF_ENV):]\n",
    "rest.loc[desc.str.startswith(PREF_LES_POR)] = rest.loc[desc.str.startswith(PREF_LES_POR)].str[len(PREF_LES_POR):]\n",
    "rest.loc[desc.str.startswith(PREF_LES_AL)]  = rest.loc[desc.str.startswith(PREF_LES_AL)].str[len(PREF_LES_AL):]\n",
    "rest = rest.str.strip().str.lstrip(\",\").str.strip()\n",
    "\n",
    "# Lugares válidos (sin comillas, sin espacios tras coma)\n",
    "LUGARES_VALIDOS = sorted([\n",
    "    \"VIVIENDA\",\n",
    "    \"INSTITUCION RESIDENCIAL\",\n",
    "    \"ESCUELAS,OTRAS INSTITUCIONES Y AREAS ADMINISTRATIVAS PUBLICAS\",\n",
    "    \"AREAS DE DEPORTE Y ATLETISMO\",\n",
    "    \"CALLES Y CARRETERAS\",\n",
    "    \"COMERCIO Y AREA DE SERVICIOS\",\n",
    "    \"AREA INDUSTRIAL Y DE LA CONSTRUCCION\",\n",
    "    \"GRANJA\",\n",
    "    \"OTRO LUGAR ESPECIFICADO\",\n",
    "    \"LUGAR NO ESPECIFICADO\",\n",
    "], key=len, reverse=True)\n",
    "\n",
    "def extraer_modo_lugar(txt: str):\n",
    "    if not isinstance(txt, str) or txt.strip() == \"\":\n",
    "        return (pd.NA, pd.NA)\n",
    "    t = txt.strip()\n",
    "    for lug in LUGARES_VALIDOS:\n",
    "        if t.endswith(lug):\n",
    "            modo = t[:-len(lug)].rstrip()\n",
    "            modo = re.sub(r\"[,\\s]+$\", \"\", modo).strip()\n",
    "            return (modo if modo else pd.NA, lug)\n",
    "    # fallback\n",
    "    if \",\" in t:\n",
    "        a, b = t.rsplit(\",\", 1)\n",
    "        return (a.strip() if a.strip() else pd.NA, b.strip() if b.strip() else pd.NA)\n",
    "    return (t, pd.NA)\n",
    "\n",
    "modo_lugar = rest.apply(extraer_modo_lugar)\n",
    "modo  = modo_lugar.apply(lambda x: x[0])\n",
    "lugar = modo_lugar.apply(lambda x: x[1])\n",
    "\n",
    "df_bridge = pd.DataFrame({\n",
    "    \"Codigo\": df[\"Codigo\"].astype(str).str.strip(),\n",
    "    \"Tipo\": tipo,\n",
    "    \"Modo\": modo,\n",
    "    \"Lugar\": lugar\n",
    "})\n",
    "\n",
    "df_bridge.to_csv(RUTA_OUT, index=False, encoding=\"utf-8\")\n",
    "RUTA_OUT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77035db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Contenido/2025_12/Suicidios_Navidad/Repositorio/Output/Suicidios_Clean.csv')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Paso 2 - Limpieza (NO imports, NO lecturas)\n",
    "# ================================================================\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def _norm_icd10(s: pd.Series) -> pd.Series:\n",
    "    return (\n",
    "        s.astype(str)\n",
    "         .str.upper()\n",
    "         .str.strip()\n",
    "         .str.replace(r\"\\.\", \"\", regex=True)\n",
    "         .str.replace(r\"\\s+\", \"\", regex=True)\n",
    "    )\n",
    "\n",
    "def _is_between_icd10(code_norm: pd.Series, ini: str, fin: str) -> pd.Series:\n",
    "    c3 = code_norm.str.slice(0, 3)  # XNN\n",
    "    return (c3 >= ini) & (c3 <= fin)\n",
    "\n",
    "def _mk_cve_mun(ent: pd.Series, mun: pd.Series) -> pd.Series:\n",
    "    return ent.astype(str).str.zfill(2) + mun.astype(str).str.zfill(3)\n",
    "\n",
    "def _parse_edad(edad_raw: pd.Series) -> pd.Series:\n",
    "    s = edad_raw.astype(str).str.strip().str.zfill(4)\n",
    "    pref = s.str[0]\n",
    "    out = pd.Series([pd.NA] * len(s), index=s.index, dtype=\"Int64\")\n",
    "    mask_ok = pref.eq(\"4\")\n",
    "    years = pd.to_numeric(s[mask_ok].str[1:4], errors=\"coerce\")\n",
    "    out.loc[mask_ok] = years.astype(\"Int64\")\n",
    "    return out\n",
    "\n",
    "def _map_from_catalog(df_cat: pd.DataFrame, key_col=\"cve\", val_col=\"descrip\") -> dict:\n",
    "    tmp = df_cat.copy()\n",
    "    tmp[key_col] = tmp[key_col].astype(str).str.strip()\n",
    "    tmp[val_col] = tmp[val_col].astype(str).str.strip()\n",
    "    return dict(zip(tmp[key_col], tmp[val_col]))\n",
    "\n",
    "def _zona_tipo_no_metro(tloc_series: pd.Series, rural_set: set) -> pd.Series:\n",
    "    t = pd.to_numeric(tloc_series, errors=\"coerce\")\n",
    "    def f(x):\n",
    "        if pd.isna(x):\n",
    "            return \"no_metropolitana_sin_tloc\"\n",
    "        return \"rural\" if int(x) in rural_set else \"urbana_no_metropolitana\"\n",
    "    return t.apply(f)\n",
    "\n",
    "def _desc_1_2_8_9(x):\n",
    "    return {1: \"si\", 2: \"no\", 8: \"no_aplica\", 9: \"no_especificado\"}.get(x, pd.NA)\n",
    "\n",
    "# -------------------------\n",
    "# 0) Normalizar insumos mínimos\n",
    "# -------------------------\n",
    "# Bridge municipal->ZM (NO lo reutilizamos mutado; guardamos base)\n",
    "df_bridge_base = df_bridge.copy()\n",
    "df_bridge_base[\"Cve_Metro\"] = df_bridge_base[\"Cve_Metro\"].astype(str).str.strip()\n",
    "df_bridge_base[\"Cve_mun\"]   = df_bridge_base[\"Cve_mun\"].astype(str).str.strip().str.zfill(5)\n",
    "\n",
    "# Bridge ICD-10 suicidio\n",
    "df_icd_bridge = df_icd_bridge.copy()\n",
    "df_icd_bridge[\"Codigo\"] = df_icd_bridge[\"Codigo\"].astype(str).str.strip().str.upper()\n",
    "# (Modo/Lugar/Tipo como texto limpio)\n",
    "for c in [\"Tipo\", \"Modo\", \"Lugar\"]:\n",
    "    if c in df_icd_bridge.columns:\n",
    "        df_icd_bridge[c] = df_icd_bridge[c].astype(str).str.strip()\n",
    "\n",
    "# Catálogos a dict\n",
    "map_paises = _map_from_catalog(df_paises, \"cve\", \"descrip\")\n",
    "map_ocup = _map_from_catalog(df_ocup, \"cve\", \"descrip\")\n",
    "map_esco = _map_from_catalog(df_esco, \"CVE\", \"DESCRIP\")\n",
    "map_eciv = _map_from_catalog(df_eciv, \"CVE\", \"DESCRIP\")\n",
    "\n",
    "# -------------------------\n",
    "# 1) Filtrado suicidio X60–X84 (todo el año) + columnas relevantes\n",
    "# -------------------------\n",
    "df_edr = df_edr.copy()\n",
    "df_edr[\"causa_def_norm\"] = _norm_icd10(df_edr[\"causa_def\"])\n",
    "mask_suic = _is_between_icd10(df_edr[\"causa_def_norm\"], ICD10_INI, ICD10_FIN)\n",
    "\n",
    "cols_keep = [\n",
    "    # causa\n",
    "    \"causa_def\", \"causa_def_norm\",\n",
    "    # tiempo\n",
    "    \"dia_ocurr\", \"mes_ocurr\", \"horas\",\n",
    "    # ocurrencia\n",
    "    \"ent_ocurr\", \"mun_ocurr\", \"tloc_ocurr\",\n",
    "    # residencia\n",
    "    \"ent_resid\", \"mun_resid\",\n",
    "    # lesión\n",
    "    \"ent_ocules\", \"mun_ocules\",\n",
    "    # socio-demo\n",
    "    \"sexo\", \"afromex\", \"conindig\", \"nacionalidad\", \"nacesp_cve\",\n",
    "    \"edad\", \"Ocupacion\", \"escolarida\", \"edo_civil\",\n",
    "]\n",
    "cols_keep = [c for c in cols_keep if c in df_edr.columns]\n",
    "\n",
    "df_suic = df_edr.loc[mask_suic, cols_keep].copy()\n",
    "\n",
    "# -------------------------\n",
    "# 1.1) Añadir bridge ICD (Codigo, Tipo, Modo, Lugar)\n",
    "# -------------------------\n",
    "# Nota: tu causa_def es C(4): letra + 3 números (ej. X700). Usamos causa_def_norm.\n",
    "# Si causa_def_norm trae algo más largo, cortamos a 4 para empatar con Codigo.\n",
    "df_suic[\"Codigo\"] = df_suic[\"causa_def_norm\"].str.slice(0, 4)\n",
    "\n",
    "df_suic = df_suic.merge(\n",
    "    df_icd_bridge[[\"Codigo\", \"Tipo\", \"Modo\", \"Lugar\"]],\n",
    "    on=\"Codigo\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 2) Join por ZM (residencia / ocurrencia / lesión)\n",
    "# -------------------------\n",
    "df_suic[\"Cve_mun_ocurr\"] = _mk_cve_mun(df_suic[\"ent_ocurr\"], df_suic[\"mun_ocurr\"])\n",
    "df_suic[\"Cve_mun_resid\"] = _mk_cve_mun(df_suic[\"ent_resid\"], df_suic[\"mun_resid\"])\n",
    "\n",
    "if (\"ent_ocules\" in df_suic.columns) and (\"mun_ocules\" in df_suic.columns):\n",
    "    df_suic[\"Cve_mun_lesion\"] = _mk_cve_mun(df_suic[\"ent_ocules\"], df_suic[\"mun_ocules\"])\n",
    "else:\n",
    "    df_suic[\"Cve_mun_lesion\"] = pd.NA\n",
    "\n",
    "# Ocurrencia → metro\n",
    "df_suic = df_suic.merge(\n",
    "    df_bridge_base.rename(columns={\"Cve_mun\": \"Cve_mun_ocurr\", \"Cve_Metro\": \"Cve_Metro_ocurr\"}),\n",
    "    on=\"Cve_mun_ocurr\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "# Residencia → metro\n",
    "df_suic = df_suic.merge(\n",
    "    df_bridge_base.rename(columns={\"Cve_mun\": \"Cve_mun_resid\", \"Cve_Metro\": \"Cve_Metro_resid\"}),\n",
    "    on=\"Cve_mun_resid\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "# Lesión → metro\n",
    "df_suic = df_suic.merge(\n",
    "    df_bridge_base.rename(columns={\"Cve_mun\": \"Cve_mun_lesion\", \"Cve_Metro\": \"Cve_Metro_lesion\"}),\n",
    "    on=\"Cve_mun_lesion\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "# Tipo de zona\n",
    "mask_no_metro_ocurr = df_suic[\"Cve_Metro_ocurr\"].isna()\n",
    "df_suic.loc[~mask_no_metro_ocurr, \"TipoZona_ocurr\"] = \"metropolitana\"\n",
    "df_suic.loc[mask_no_metro_ocurr, \"TipoZona_ocurr\"] = _zona_tipo_no_metro(df_suic.loc[mask_no_metro_ocurr, \"tloc_ocurr\"], RURAL_TLOC)\n",
    "\n",
    "df_suic[\"TipoZona_resid\"] = df_suic[\"Cve_Metro_resid\"].apply(lambda x: \"metropolitana\" if pd.notna(x) else \"no_metropolitana\")\n",
    "df_suic[\"TipoZona_lesion\"] = df_suic[\"Cve_Metro_lesion\"].apply(lambda x: \"metropolitana\" if pd.notna(x) else \"no_metropolitana\")\n",
    "\n",
    "# Banderas útiles\n",
    "df_suic[\"ocurr_fuera_metro_resid\"] = (\n",
    "    df_suic[\"Cve_Metro_resid\"].notna() &\n",
    "    (df_suic[\"Cve_Metro_ocurr\"].fillna(\"NA\") != df_suic[\"Cve_Metro_resid\"])\n",
    ")\n",
    "\n",
    "df_suic[\"lesion_fuera_metro_resid\"] = (\n",
    "    df_suic[\"Cve_Metro_resid\"].notna() &\n",
    "    (df_suic[\"Cve_Metro_lesion\"].fillna(\"NA\") != df_suic[\"Cve_Metro_resid\"])\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 3) Homogenization: columnas espejo (código + descripción)\n",
    "# -------------------------\n",
    "# sexo\n",
    "df_suic[\"sexo_code\"] = pd.to_numeric(df_suic.get(\"sexo\"), errors=\"coerce\")\n",
    "df_suic[\"sexo_desc\"] = df_suic[\"sexo_code\"].map({1: \"hombre\", 2: \"mujer\", 9: \"no_especificado\"})\n",
    "\n",
    "# afromex / conindig\n",
    "for col in [\"afromex\", \"conindig\"]:\n",
    "    if col in df_suic.columns:\n",
    "        code = pd.to_numeric(df_suic[col], errors=\"coerce\")\n",
    "        df_suic[col + \"_code\"] = code\n",
    "        df_suic[col + \"_desc\"] = code.apply(_desc_1_2_8_9)\n",
    "\n",
    "# nacionalidad\n",
    "if \"nacionalidad\" in df_suic.columns:\n",
    "    ncode = pd.to_numeric(df_suic[\"nacionalidad\"], errors=\"coerce\")\n",
    "    df_suic[\"nacionalidad_code\"] = ncode\n",
    "    df_suic[\"nacionalidad_desc\"] = ncode.map({1: \"mexicana\", 2: \"extranjera\", 9: \"no_especificado\"})\n",
    "\n",
    "# país nacimiento (si es extranjera, esto te sirve mucho)\n",
    "if \"nacesp_cve\" in df_suic.columns:\n",
    "    df_suic[\"nacesp_cve_code\"] = df_suic[\"nacesp_cve\"].astype(str).str.strip()\n",
    "    df_suic[\"nacesp_pais_desc\"] = df_suic[\"nacesp_cve_code\"].map(map_paises)\n",
    "\n",
    "# edad\n",
    "if \"edad\" in df_suic.columns:\n",
    "    df_suic[\"edad_raw\"] = df_suic[\"edad\"]\n",
    "    df_suic[\"edad_anios\"] = _parse_edad(df_suic[\"edad\"])\n",
    "\n",
    "# ocupación\n",
    "if \"Ocupacion\" in df_suic.columns:\n",
    "    df_suic[\"ocupacion_code\"] = df_suic[\"Ocupacion\"].astype(str).str.strip()\n",
    "    df_suic[\"ocupacion_desc\"] = df_suic[\"ocupacion_code\"].map(map_ocup)\n",
    "\n",
    "# escolaridad\n",
    "if \"escolarida\" in df_suic.columns:\n",
    "    df_suic[\"escolarida_code\"] = df_suic[\"escolarida\"].astype(str).str.strip()\n",
    "    df_suic[\"escolarida_desc\"] = df_suic[\"escolarida_code\"].map(map_esco)\n",
    "\n",
    "# estado civil\n",
    "if \"edo_civil\" in df_suic.columns:\n",
    "    df_suic[\"edo_civil_code\"] = df_suic[\"edo_civil\"].astype(str).str.strip()\n",
    "    df_suic[\"edo_civil_desc\"] = df_suic[\"edo_civil_code\"].map(map_eciv)\n",
    "\n",
    "# día/mes/hora\n",
    "if \"dia_ocurr\" in df_suic.columns:\n",
    "    d = pd.to_numeric(df_suic[\"dia_ocurr\"], errors=\"coerce\")\n",
    "    df_suic[\"dia_ocurr_code\"] = d\n",
    "    df_suic[\"dia\"] = d.where((d >= 1) & (d <= 31), pd.NA).astype(\"Int64\")\n",
    "\n",
    "if \"mes_ocurr\" in df_suic.columns:\n",
    "    m = pd.to_numeric(df_suic[\"mes_ocurr\"], errors=\"coerce\")\n",
    "    df_suic[\"mes_ocurr_code\"] = m\n",
    "    df_suic[\"mes\"] = m.where((m >= 1) & (m <= 12), pd.NA).astype(\"Int64\")\n",
    "\n",
    "if \"horas\" in df_suic.columns:\n",
    "    h = pd.to_numeric(df_suic[\"horas\"], errors=\"coerce\")\n",
    "    df_suic[\"hora_code\"] = h\n",
    "    df_suic[\"hora\"] = h.where((h >= 0) & (h <= 23), pd.NA).astype(\"Int64\")\n",
    "\n",
    "# -------------------------\n",
    "# 4) Output clean (df listo)\n",
    "# -------------------------\n",
    "df_clean = df_suic.copy()\n",
    "\n",
    "OUT_CLEAN.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_clean.to_csv(OUT_CLEAN, index=False, encoding=\"utf-8\")\n",
    "OUT_CLEAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eac5b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A nivel nacional este rango de fechas [no] fue cuando más defunciones por este motivo se registraron con 256. El segundo rango fue de 19/04 a 26/04 con 255 defunciones.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan Pablo\\AppData\\Local\\Temp\\ipykernel_5236\\2110503537.py:114: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(_summarize_one_metro)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Contenido/2025_12/Suicidios_Navidad/Repositorio/Output/AnalisisVentanas8d_ZM.csv')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Paso 3.1 - Ventanas móviles de 8 días (Nacional + por ZM)\n",
    "# ================================================================\n",
    "\n",
    "BASE_ZM = \"resid\"  # \"resid\" o \"ocurr\"\n",
    "col_metro = \"Cve_Metro_resid\" if BASE_ZM == \"resid\" else \"Cve_Metro_ocurr\"\n",
    "\n",
    "NAV_START = (12, 24)\n",
    "NAV_END   = (12, 31)\n",
    "YEAR_FAKE = 2024  # año fijo para ordenar; EDR 2024\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def _make_date(df, year=2024):\n",
    "    d = df.copy()\n",
    "    d = d[d[\"mes\"].notna() & d[\"dia\"].notna()].copy()\n",
    "    d[\"mes_i\"] = d[\"mes\"].astype(int)\n",
    "    d[\"dia_i\"] = d[\"dia\"].astype(int)\n",
    "    d = d[(d[\"mes_i\"] >= 1) & (d[\"mes_i\"] <= 12) & (d[\"dia_i\"] >= 1) & (d[\"dia_i\"] <= 31)].copy()\n",
    "    d[\"fecha\"] = pd.to_datetime({\"year\": year, \"month\": d[\"mes_i\"], \"day\": d[\"dia_i\"]}, errors=\"coerce\")\n",
    "    return d[d[\"fecha\"].notna()].copy()\n",
    "\n",
    "def _top_k_windows(daily_counts, k=3, window=8):\n",
    "    s = daily_counts.sort_index().astype(int)\n",
    "    roll = s.rolling(window=window, min_periods=window).sum().dropna()\n",
    "    if roll.empty:\n",
    "        return []\n",
    "    top_end = roll.sort_values(ascending=False).head(k).index\n",
    "    out = []\n",
    "    for end in top_end:\n",
    "        start = end - pd.Timedelta(days=window - 1)\n",
    "        out.append({\"start\": start, \"end\": end, \"count\": int(roll.loc[end])})\n",
    "    return out\n",
    "\n",
    "def _fixed_window_sum(daily_counts, start_md, end_md, year=2024):\n",
    "    start = pd.Timestamp(year=year, month=start_md[0], day=start_md[1])\n",
    "    end   = pd.Timestamp(year=year, month=end_md[0], day=end_md[1])\n",
    "    s = daily_counts.sort_index().astype(int)\n",
    "    return int(s.loc[(s.index >= start) & (s.index <= end)].sum())\n",
    "\n",
    "def _rank_of_window(top_list, start_dt, end_dt):\n",
    "    # rank 1..len(top_list) si coincide EXACTO con top window. Si no, 0.\n",
    "    for i, w in enumerate(top_list, start=1):\n",
    "        if (w[\"start\"] == start_dt) and (w[\"end\"] == end_dt):\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "# -------------------------\n",
    "# Nacional: primer print (top1 vs navidad)\n",
    "# -------------------------\n",
    "df_base = _make_date(df_clean.copy(), year=YEAR_FAKE)\n",
    "daily_nat = df_base.groupby(\"fecha\").size()\n",
    "\n",
    "top2_nat = _top_k_windows(daily_nat, k=2, window=8)\n",
    "nav_start_dt = pd.Timestamp(YEAR_FAKE, NAV_START[0], NAV_START[1])\n",
    "nav_end_dt   = pd.Timestamp(YEAR_FAKE, NAV_END[0], NAV_END[1])\n",
    "nav_nat = _fixed_window_sum(daily_nat, NAV_START, NAV_END, year=YEAR_FAKE)\n",
    "\n",
    "if len(top2_nat) >= 2:\n",
    "    is_nav_top1_nat = (nav_nat == top2_nat[0][\"count\"])\n",
    "    print(\n",
    "        f\"A nivel nacional este rango de fechas [{'si' if is_nav_top1_nat else 'no'}] \"\n",
    "        f\"fue cuando más defunciones por este motivo se registraron con {top2_nat[0]['count']}. \"\n",
    "        f\"El segundo rango fue de {top2_nat[1]['start'].strftime('%d/%m')} a {top2_nat[1]['end'].strftime('%d/%m')} \"\n",
    "        f\"con {top2_nat[1]['count']} defunciones.\"\n",
    "    )\n",
    "elif len(top2_nat) == 1:\n",
    "    is_nav_top1_nat = (nav_nat == top2_nat[0][\"count\"])\n",
    "    print(\n",
    "        f\"A nivel nacional este rango de fechas [{'si' if is_nav_top1_nat else 'no'}] \"\n",
    "        f\"fue cuando más defunciones por este motivo se registraron con {top2_nat[0]['count']}. \"\n",
    "        \"No hubo un segundo rango disponible.\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No se pudieron calcular ventanas nacionales de 8 días (fechas insuficientes o inválidas).\")\n",
    "\n",
    "# -------------------------\n",
    "# Por ZM: construir daily counts\n",
    "# -------------------------\n",
    "df_m = df_base[df_base[col_metro].notna()].copy()\n",
    "g = df_m.groupby([col_metro, \"fecha\"]).size().rename(\"n\").reset_index()\n",
    "\n",
    "def _summarize_one_metro(df_one):\n",
    "    s = df_one.set_index(\"fecha\")[\"n\"].sort_index()\n",
    "    top3 = _top_k_windows(s, k=3, window=8)\n",
    "    total = int(s.sum())\n",
    "    nav_cnt = _fixed_window_sum(s, NAV_START, NAV_END, year=YEAR_FAKE)\n",
    "\n",
    "    def get_i(i):\n",
    "        if i < len(top3):\n",
    "            return top3[i][\"start\"], top3[i][\"end\"], top3[i][\"count\"]\n",
    "        return (pd.NaT, pd.NaT, pd.NA)\n",
    "\n",
    "    t1s, t1e, t1c = get_i(0)\n",
    "    t2s, t2e, t2c = get_i(1)\n",
    "    t3s, t3e, t3c = get_i(2)\n",
    "\n",
    "    nav_rank = _rank_of_window(top3, nav_start_dt, nav_end_dt)  # 1/2/3 o 0\n",
    "\n",
    "    return pd.Series({\n",
    "        \"Suicidios_totales\": total,\n",
    "        \"Navidad_24_31_dic\": nav_cnt,\n",
    "        \"Navidad_rank\": nav_rank,\n",
    "        \"Navidad_es_top1\": (nav_rank == 1),\n",
    "\n",
    "        \"Top1_inicio\": t1s, \"Top1_fin\": t1e, \"Top1_suicidios\": t1c,\n",
    "        \"Top2_inicio\": t2s, \"Top2_fin\": t2e, \"Top2_suicidios\": t2c,\n",
    "        \"Top3_inicio\": t3s, \"Top3_fin\": t3e, \"Top3_suicidios\": t3c,\n",
    "    })\n",
    "\n",
    "df_metro_windows = (\n",
    "    g.groupby(col_metro, as_index=True)\n",
    "     .apply(_summarize_one_metro)\n",
    "     .reset_index()\n",
    "     .rename(columns={col_metro: \"Cve_Metro\"})\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Join con nombre/población (desde df_zm_pob creado en Paso 1.1)\n",
    "# -------------------------\n",
    "df_meta = df_zm_pob.copy()\n",
    "df_meta = df_meta.rename(columns={\"clave_metropoli\": \"Cve_Metro\", \"nombre\": \"Nombre\", \"poblacion2024\": \"Poblacion\"})\n",
    "df_meta[\"Cve_Metro\"] = df_meta[\"Cve_Metro\"].astype(str).str.strip()\n",
    "\n",
    "df_out = df_metro_windows.merge(\n",
    "    df_meta[[\"Cve_Metro\", \"Nombre\", \"Poblacion\"]],\n",
    "    on=\"Cve_Metro\",\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\"\n",
    ")\n",
    "\n",
    "df_out[\"Tasa_100k\"] = (df_out[\"Suicidios_totales\"] / df_out[\"Poblacion\"]) * 100_000\n",
    "\n",
    "# -------------------------\n",
    "# Exportar TODAS las ZM\n",
    "# -------------------------\n",
    "# Orden de columnas\n",
    "cols = [\n",
    "    \"Cve_Metro\", \"Nombre\", \"Poblacion\",\n",
    "    \"Suicidios_totales\", \"Tasa_100k\",\n",
    "    \"Navidad_24_31_dic\", \"Navidad_rank\", \"Navidad_es_top1\",\n",
    "    \"Top1_inicio\", \"Top1_fin\", \"Top1_suicidios\",\n",
    "    \"Top2_inicio\", \"Top2_fin\", \"Top2_suicidios\",\n",
    "    \"Top3_inicio\", \"Top3_fin\", \"Top3_suicidios\",\n",
    "]\n",
    "df_out = df_out[[c for c in cols if c in df_out.columns]].copy()\n",
    "\n",
    "df_out.to_csv(OUT_ANALISIS_ZM, index=False, encoding=\"utf-8\")\n",
    "OUT_ANALISIS_ZM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cac55e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NACIONAL: Navidad (24-31 dic) tuvo 187 casos. Percentil=0.384 (0=bajo, 1=alto), RobustZ(MAD)=-0.30. Top1 fue 256 del 15/04 al 22/04.\n",
      "GRUPOS: Mayor outlier positivo en Navidad: escolarida_desc=Secundaria completa | RobustZ=1.48 | Percentil=0.877 | nav_count=65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan Pablo\\AppData\\Local\\Temp\\ipykernel_5236\\1465254666.py:202: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for val, df_sub in df_base.groupby(gv, dropna=False):\n",
      "C:\\Users\\Juan Pablo\\AppData\\Local\\Temp\\ipykernel_5236\\1465254666.py:230: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(summarize_one_metro)\n",
      "C:\\Users\\Juan Pablo\\AppData\\Local\\Temp\\ipykernel_5236\\1465254666.py:261: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  ct = df_m.groupby([COL_ZM, gv]).size().rename(\"n_events\").reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exports:\n",
      "D:\\Contenido\\2025_12\\Suicidios_Navidad\\Repositorio\\Output\\OutlierNavidad_Nacional.csv\n",
      "D:\\Contenido\\2025_12\\Suicidios_Navidad\\Repositorio\\Output\\OutlierNavidad_Grupos_Nacional.csv\n",
      "D:\\Contenido\\2025_12\\Suicidios_Navidad\\Repositorio\\Output\\OutlierNavidad_ZM.csv\n",
      "D:\\Contenido\\2025_12\\Suicidios_Navidad\\Repositorio\\Output\\OutlierNavidad_ZM_Grupos.csv\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Paso 3.2 - ¿Navidad es outlier? (8 días) Nacional + Grupos + ZM\n",
    "# Puede leer aquí archivos sin re-correr el bloque 0.\n",
    "# ================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------\n",
    "# Rutas (ajusta si tu DIR_REPO ya existe en memoria)\n",
    "# -------------------------\n",
    "try:\n",
    "    DIR_REPO\n",
    "except NameError:\n",
    "    DIR_REPO = Path(r\"D:\\Contenido\\2025_12\\Suicidios_Navidad\\Repositorio\")\n",
    "\n",
    "DIR_OUTPUT = DIR_REPO / \"Output\"\n",
    "RUTA_CLEAN = DIR_OUTPUT / \"Suicidios_Clean.csv\"\n",
    "RUTA_POB_ZM = DIR_OUTPUT / \"ZonaMetro_Pob2024.csv\"\n",
    "\n",
    "OUT_NACIONAL = DIR_OUTPUT / \"OutlierNavidad_Nacional.csv\"\n",
    "OUT_GRUPOS = DIR_OUTPUT / \"OutlierNavidad_Grupos_Nacional.csv\"\n",
    "OUT_ZM = DIR_OUTPUT / \"OutlierNavidad_ZM.csv\"\n",
    "OUT_ZM_GRUPOS = DIR_OUTPUT / \"OutlierNavidad_ZM_Grupos.csv\"\n",
    "\n",
    "# -------------------------\n",
    "# Parámetros ventana\n",
    "# -------------------------\n",
    "WINDOW = 8\n",
    "YEAR_FAKE = 2024\n",
    "NAV_START = (12, 24)\n",
    "NAV_END = (12, 31)\n",
    "nav_start_dt = pd.Timestamp(YEAR_FAKE, NAV_START[0], NAV_START[1])\n",
    "nav_end_dt   = pd.Timestamp(YEAR_FAKE, NAV_END[0], NAV_END[1])\n",
    "\n",
    "# Base geográfica (elige una)\n",
    "BASE_ZM = \"resid\"   # \"resid\" o \"ocurr\"\n",
    "COL_ZM = \"Cve_Metro_resid\" if BASE_ZM == \"resid\" else \"Cve_Metro_ocurr\"\n",
    "\n",
    "# -------------------------\n",
    "# Cargar df_clean si no existe\n",
    "# -------------------------\n",
    "if \"df_clean\" not in globals():\n",
    "    df_clean = pd.read_csv(RUTA_CLEAN, encoding=\"utf-8\", low_memory=False)\n",
    "\n",
    "# Población ZM (para tasa total; opcional)\n",
    "df_pob = None\n",
    "if RUTA_POB_ZM.exists():\n",
    "    df_pob = pd.read_csv(RUTA_POB_ZM, encoding=\"utf-8\")\n",
    "    df_pob[\"clave_metropoli\"] = df_pob[\"clave_metropoli\"].astype(str).str.strip()\n",
    "    if \"poblacion2024\" in df_pob.columns:\n",
    "        df_pob[\"poblacion2024\"] = pd.to_numeric(df_pob[\"poblacion2024\"], errors=\"coerce\")\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def make_date(df, year=2024):\n",
    "    d = df.copy()\n",
    "    # usa columnas ya limpias si existen\n",
    "    if \"mes\" in d.columns and \"dia\" in d.columns:\n",
    "        m = pd.to_numeric(d[\"mes\"], errors=\"coerce\")\n",
    "        di = pd.to_numeric(d[\"dia\"], errors=\"coerce\")\n",
    "    else:\n",
    "        m = pd.to_numeric(d[\"mes_ocurr\"], errors=\"coerce\")\n",
    "        di = pd.to_numeric(d[\"dia_ocurr\"], errors=\"coerce\")\n",
    "\n",
    "    d = d.assign(_mes=m, _dia=di)\n",
    "    d = d[d[\"_mes\"].between(1, 12) & d[\"_dia\"].between(1, 31)].copy()\n",
    "\n",
    "    d[\"fecha\"] = pd.to_datetime(\n",
    "        {\"year\": year, \"month\": d[\"_mes\"].astype(int), \"day\": d[\"_dia\"].astype(int)},\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    d = d[d[\"fecha\"].notna()].copy()\n",
    "    return d\n",
    "\n",
    "def daily_counts(df, group_cols=None):\n",
    "    if group_cols is None:\n",
    "        return df.groupby(\"fecha\").size().sort_index()\n",
    "    return df.groupby(group_cols + [\"fecha\"]).size().rename(\"n\").reset_index()\n",
    "\n",
    "def rolling_windows_series(daily_series, window=8):\n",
    "    s = daily_series.sort_index().astype(int)\n",
    "    roll = s.rolling(window=window, min_periods=window).sum().dropna()\n",
    "    # index = end date\n",
    "    return roll\n",
    "\n",
    "def fixed_window_sum(daily_series, start_dt, end_dt):\n",
    "    s = daily_series.sort_index().astype(int)\n",
    "    return int(s.loc[(s.index >= start_dt) & (s.index <= end_dt)].sum())\n",
    "\n",
    "def robust_z_mad(values, x):\n",
    "    \"\"\"\n",
    "    values: array-like de conteos (todas las ventanas)\n",
    "    x: conteo en navidad\n",
    "    Retorna robust z usando MAD. Si MAD=0, regresa NaN.\n",
    "    \"\"\"\n",
    "    v = np.asarray(values, dtype=float)\n",
    "    med = np.nanmedian(v)\n",
    "    mad = np.nanmedian(np.abs(v - med))\n",
    "    if mad == 0 or np.isnan(mad):\n",
    "        return np.nan\n",
    "    return (x - med) / (1.4826 * mad)\n",
    "\n",
    "def percentile_of_x(values, x):\n",
    "    v = np.asarray(values, dtype=float)\n",
    "    v = v[~np.isnan(v)]\n",
    "    if len(v) == 0:\n",
    "        return np.nan\n",
    "    return float((v <= x).mean())\n",
    "\n",
    "def summarize_outlier_from_daily(daily_series, label=\"total\"):\n",
    "    \"\"\"\n",
    "    daily_series: Series index=fecha, values=conteos por día\n",
    "    \"\"\"\n",
    "    roll = rolling_windows_series(daily_series, window=WINDOW)  # windows by end-date\n",
    "    if roll.empty:\n",
    "        return pd.Series({\n",
    "            \"grupo\": label,\n",
    "            \"nav_count\": 0,\n",
    "            \"nav_percentile\": np.nan,\n",
    "            \"nav_robust_z\": np.nan,\n",
    "            \"top1_count\": np.nan,\n",
    "            \"top1_start\": pd.NaT,\n",
    "            \"top1_end\": pd.NaT,\n",
    "            \"n_windows\": 0\n",
    "        })\n",
    "\n",
    "    # nav count fijo 24-31\n",
    "    nav_cnt = fixed_window_sum(daily_series, nav_start_dt, nav_end_dt)\n",
    "\n",
    "    # percentil / robust z vs todas las ventanas\n",
    "    vals = roll.values\n",
    "    nav_pct = percentile_of_x(vals, nav_cnt)\n",
    "    nav_rz = robust_z_mad(vals, nav_cnt)\n",
    "\n",
    "    # top1\n",
    "    end_top1 = roll.idxmax()\n",
    "    top1_cnt = int(roll.loc[end_top1])\n",
    "    top1_start = end_top1 - pd.Timedelta(days=WINDOW - 1)\n",
    "    top1_end = end_top1\n",
    "\n",
    "    return pd.Series({\n",
    "        \"grupo\": label,\n",
    "        \"nav_count\": int(nav_cnt),\n",
    "        \"nav_percentile\": nav_pct,\n",
    "        \"nav_robust_z\": nav_rz,\n",
    "        \"top1_count\": top1_cnt,\n",
    "        \"top1_start\": top1_start,\n",
    "        \"top1_end\": top1_end,\n",
    "        \"n_windows\": int(len(roll))\n",
    "    })\n",
    "\n",
    "# -------------------------\n",
    "# 1) Nacional (total)\n",
    "# -------------------------\n",
    "df_base = make_date(df_clean, year=YEAR_FAKE)\n",
    "daily_nat = daily_counts(df_base)\n",
    "\n",
    "res_nat = summarize_outlier_from_daily(daily_nat, label=\"nacional_total\")\n",
    "\n",
    "# Imprime el headline\n",
    "# (si nav_percentile ~ 1.0 => navidad arriba; ~0.0 => abajo)\n",
    "print(\n",
    "    f\"NACIONAL: Navidad (24-31 dic) tuvo {res_nat['nav_count']} casos. \"\n",
    "    f\"Percentil={res_nat['nav_percentile']:.3f} (0=bajo, 1=alto), \"\n",
    "    f\"RobustZ(MAD)={res_nat['nav_robust_z']:.2f}. \"\n",
    "    f\"Top1 fue {int(res_nat['top1_count'])} del {res_nat['top1_start'].strftime('%d/%m')} al {res_nat['top1_end'].strftime('%d/%m')}.\"\n",
    ")\n",
    "\n",
    "pd.DataFrame([res_nat]).to_csv(OUT_NACIONAL, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# -------------------------\n",
    "# 2) Nacional por grupos\n",
    "# -------------------------\n",
    "# Definir grupos (ajusta a tus columnas disponibles)\n",
    "df_base = df_base.copy()\n",
    "\n",
    "# edad en bandas (usa edad_anios si existe; si no, intenta construirlo desde edad_raw)\n",
    "if \"edad_anios\" in df_base.columns:\n",
    "    edad = pd.to_numeric(df_base[\"edad_anios\"], errors=\"coerce\")\n",
    "elif \"edad_raw\" in df_base.columns:\n",
    "    # fallback: si tienes edad_raw en formato 4xxx\n",
    "    s = df_base[\"edad_raw\"].astype(str).str.strip().str.zfill(4)\n",
    "    edad = pd.to_numeric(s.where(s.str.startswith(\"4\")).str[1:4], errors=\"coerce\")\n",
    "else:\n",
    "    edad = pd.Series(np.nan, index=df_base.index)\n",
    "\n",
    "bins = [0, 14, 24, 34, 44, 54, 64, 74, 200]\n",
    "labels = [\"0-14\",\"15-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65-74\",\"75+\"]\n",
    "df_base[\"edad_grupo\"] = pd.cut(edad, bins=bins, labels=labels, right=True, include_lowest=True)\n",
    "\n",
    "# columnas de grupo (solo si existen)\n",
    "group_vars = []\n",
    "for c in [\"sexo_desc\", \"edad_grupo\", \"escolarida_desc\", \"conindig_desc\"]:\n",
    "    if c in df_base.columns:\n",
    "        group_vars.append(c)\n",
    "\n",
    "rows = []\n",
    "for gv in group_vars:\n",
    "    for val, df_sub in df_base.groupby(gv, dropna=False):\n",
    "        daily = daily_counts(df_sub)\n",
    "        label = f\"{gv}={val}\"\n",
    "        rows.append(summarize_outlier_from_daily(daily, label=label))\n",
    "\n",
    "df_grupos = pd.DataFrame(rows)\n",
    "df_grupos.to_csv(OUT_GRUPOS, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# ¿Cuál grupo está más \"arriba\" en navidad? (robust z mayor)\n",
    "df_grupos_rank = df_grupos.dropna(subset=[\"nav_robust_z\"]).sort_values(\"nav_robust_z\", ascending=False)\n",
    "if not df_grupos_rank.empty:\n",
    "    top = df_grupos_rank.iloc[0]\n",
    "    print(f\"GRUPOS: Mayor outlier positivo en Navidad: {top['grupo']} | RobustZ={top['nav_robust_z']:.2f} | Percentil={top['nav_percentile']:.3f} | nav_count={int(top['nav_count'])}\")\n",
    "\n",
    "# -------------------------\n",
    "# 3) Geografía: por ZM (todas)\n",
    "# -------------------------\n",
    "df_m = df_base[df_base[COL_ZM].notna()].copy()\n",
    "df_m[COL_ZM] = df_m[COL_ZM].astype(str).str.strip()\n",
    "\n",
    "g = daily_counts(df_m, group_cols=[COL_ZM])\n",
    "\n",
    "def summarize_one_metro(df_one):\n",
    "    s = df_one.set_index(\"fecha\")[\"n\"].sort_index()\n",
    "    return summarize_outlier_from_daily(s, label=\"\")  # label se rellena afuera\n",
    "\n",
    "df_zm = (\n",
    "    g.groupby(COL_ZM, as_index=True)\n",
    "     .apply(summarize_one_metro)\n",
    "     .reset_index()\n",
    "     .rename(columns={COL_ZM: \"Cve_Metro\"})\n",
    ")\n",
    "\n",
    "# agregar nombre y población si existe\n",
    "if df_pob is not None:\n",
    "    meta = df_pob.rename(columns={\n",
    "        \"clave_metropoli\": \"Cve_Metro\",\n",
    "        \"nombre\": \"Nombre\",\n",
    "        \"poblacion2024\": \"Poblacion\"\n",
    "    }).copy()\n",
    "    meta[\"Cve_Metro\"] = meta[\"Cve_Metro\"].astype(str).str.strip()\n",
    "\n",
    "    df_zm = df_zm.merge(meta[[\"Cve_Metro\",\"Nombre\",\"Poblacion\"]], on=\"Cve_Metro\", how=\"left\", validate=\"one_to_one\")\n",
    "    df_zm[\"tasa_anual_100k\"] = (df_zm[\"nav_count\"] * 0 + df_zm[\"top1_count\"] * 0)  # placeholder si quieres\n",
    "    # tasa anual no se define aquí; definimos tasa NAV y/o total anual si la quieres:\n",
    "    # nota: summarize_outlier no devuelve total anual; si lo necesitas, se calcula aparte.\n",
    "\n",
    "# Export map-ready\n",
    "df_zm.to_csv(OUT_ZM, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# -------------------------\n",
    "# 4) Geografía por grupo (ZM x grupo) - útil para \"qué grupo y dónde\"\n",
    "# -------------------------\n",
    "# Esto puede crecer; lo limitamos a variables que sí existan y evitamos grupos ultra chicos.\n",
    "MIN_EVENTS = 30  # umbral para estabilidad (ajústalo)\n",
    "\n",
    "rows = []\n",
    "for gv in group_vars:\n",
    "    # contar eventos por ZM y grupo para filtrar\n",
    "    ct = df_m.groupby([COL_ZM, gv]).size().rename(\"n_events\").reset_index()\n",
    "    ct = ct[ct[\"n_events\"] >= MIN_EVENTS].copy()\n",
    "    if ct.empty:\n",
    "        continue\n",
    "\n",
    "    # iterar combos válidos\n",
    "    for _, r in ct.iterrows():\n",
    "        zm = r[COL_ZM]\n",
    "        val = r[gv]\n",
    "        sub = df_m[(df_m[COL_ZM] == zm) & (df_m[gv] == val)].copy()\n",
    "        daily = daily_counts(sub)\n",
    "        out = summarize_outlier_from_daily(daily, label=f\"{gv}={val}\")\n",
    "        out[\"Cve_Metro\"] = zm\n",
    "        out[\"variable\"] = gv\n",
    "        out[\"categoria\"] = str(val)\n",
    "        out[\"n_events\"] = int(r[\"n_events\"])\n",
    "        rows.append(out)\n",
    "\n",
    "df_zm_grupos = pd.DataFrame(rows)\n",
    "df_zm_grupos.to_csv(OUT_ZM_GRUPOS, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Exports:\")\n",
    "print(OUT_NACIONAL)\n",
    "print(OUT_GRUPOS)\n",
    "print(OUT_ZM)\n",
    "print(OUT_ZM_GRUPOS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
